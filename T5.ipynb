{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4cRE8IbIrIV"
      },
      "source": [
        "## T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5BszcKK-qNb"
      },
      "source": [
        "This notebook is adapted from HuggingFace's summarisation notebook. https://huggingface.co/transformers/notebooks.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbWWfieX9DvC"
      },
      "source": [
        "# 1. Import Modules\n",
        "# 2. Load Data\n",
        "# 3. Preprocess the Data\n",
        "# 4. Finetune the Model\n",
        "# 3. Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCLPiEAr-SQe"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d143d2-20ed-4d12-c90e-0b4d70810637"
      },
      "source": [
        "%pip install datasets transformers rouge-score nltk\n",
        "%pip install wandb\n",
        "import wandb\n",
        "%pip install optuna\n",
        "%pip install tqdm\n",
        "!pip install ray==0.8.7\n",
        "!pip install ray[tune]\n",
        "import tqdm\n",
        "import datasets\n",
        "import transformers\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from datasets import load_dataset, load_metric\n",
        "%pip install pickle5\n",
        "import pickle5 as pickle\n",
        "import os\n",
        "import torch\n",
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from ray import tune\n",
        "from transformers import AutoTokenizer\n",
        "import nltk\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: graphql-core>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.5)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.18)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.6.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (5.0.1)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.2)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.6.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.4.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: ray==0.8.7 in /usr/local/lib/python3.7/dist-packages (0.8.7)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (0.3.8)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (0.7.13)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (1.34.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (2.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (3.0.12)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (2.0.3)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (0.11.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (3.17.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (0.4.4)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (3.7.4.post0)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (2.0.0)\n",
            "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (3.4.1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (0.5.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (7.1.2)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray==0.8.7) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray==0.8.7) (1.15.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.7) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.7) (3.7.4.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.7) (5.1.0)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.7) (3.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.7) (1.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.7) (21.2.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->ray==0.8.7) (2.10)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google->ray==0.8.7) (4.6.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==0.8.7) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==0.8.7) (5.4.8)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==0.8.7) (1.7)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==0.8.7) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==0.8.7) (1.26.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (57.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (2018.9)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (1.32.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (21.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.8.7) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray==0.8.7) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray==0.8.7) (2021.5.30)\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (0.8.7)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.34.1)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.3.8)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.0.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.7.4.post0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (5.4.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.7.13)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.11.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.4.4)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.0.3)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.5.4)\n",
            "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.1.5)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (1.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (21.2.0)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (5.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->ray[tune]) (2.10)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google->ray[tune]) (4.6.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (7.352.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (5.4.8)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (57.2.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.32.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.1)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbe3JeAb68F"
      },
      "source": [
        "# define model to be used\n",
        "model_checkpoint = \"t5-small\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreSlFmlIrIm"
      },
      "source": [
        "# open a file, where you stored the pickled data\n",
        "DATA_PATH = \"/content\"\n",
        "file1 = open(DATA_PATH+'/tac_train_dataset_nodups2.pickle', 'rb')\n",
        "file2 = open(DATA_PATH+'/tac_valid_dataset_nodups2.pickle', 'rb')\n",
        "file3 = open(DATA_PATH+'/tac_test_dataset_nodups2.pickle', 'rb')\n",
        "\n",
        "# dump information to that file\n",
        "tac_train = pickle.load(file1)\n",
        "tac_valid = pickle.load(file2)\n",
        "tac_test = pickle.load(file3)\n",
        "\n",
        "metric = load_metric(\"rouge\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X65hU4AXGl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a11ab53-f5cc-47fd-addd-3dc06ead8e30"
      },
      "source": [
        "# View the training set\n",
        "tac_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Original Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>this service gives no guarantee regarding quality</td>\n",
              "      <td>any details as to products  including product descriptions  benefits  quality and performance are provided by the supplier or manufacturer of the product and are reproduced for the convenience of our users this information is not verified or substantiated by sparknotes and sparknotes is not responsible for any inaccuracies or omissions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>users may opt out of binding arbitration within 30 days of signing the agreement</td>\n",
              "      <td>if you are a new user of our services  you can choose to reject this agreement to arbitrate   opt out   by mailing us a written opt out notice   opt out notice   the opt out notice must be postmarked no later than 30 days after the date you accept the user agreement for the first time you must mail the opt out notice to ebay inc   attn  litigation department  re  opt out notice  583 west ebay way  draper  ut 84020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>the service can remove  screen  or edit your content without prior notice and without a reason</td>\n",
              "      <td>brainly reserves the right to moderate the brainly services andto remove  screen  or edit your content from the brainly services at oursole discretion  at any time  and for any reason or for no reason  with nonotice to you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>the services will notify users if its account has been affected by data breaches</td>\n",
              "      <td>you must immediately notify e foundation of any unauthorized uses of your account or any other breaches of security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>the court of law governing the terms is in location british virgin islands</td>\n",
              "      <td>this privacy policy and our privacy practices will be subject exclusively to the laws of the british virgin islands</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                            Summary                                                                                                                                                                                                                                                                                                                                                                                                                       Original Text\n",
              "456  this service gives no guarantee regarding quality                                               any details as to products  including product descriptions  benefits  quality and performance are provided by the supplier or manufacturer of the product and are reproduced for the convenience of our users this information is not verified or substantiated by sparknotes and sparknotes is not responsible for any inaccuracies or omissions                                                                                 \n",
              "505  users may opt out of binding arbitration within 30 days of signing the agreement                if you are a new user of our services  you can choose to reject this agreement to arbitrate   opt out   by mailing us a written opt out notice   opt out notice   the opt out notice must be postmarked no later than 30 days after the date you accept the user agreement for the first time you must mail the opt out notice to ebay inc   attn  litigation department  re  opt out notice  583 west ebay way  draper  ut 84020 \n",
              "55   the service can remove  screen  or edit your content without prior notice and without a reason  brainly reserves the right to moderate the brainly services andto remove  screen  or edit your content from the brainly services at oursole discretion  at any time  and for any reason or for no reason  with nonotice to you                                                                                                                                                                                                    \n",
              "682  the services will notify users if its account has been affected by data breaches                you must immediately notify e foundation of any unauthorized uses of your account or any other breaches of security                                                                                                                                                                                                                                                                                                               \n",
              "459  the court of law governing the terms is in location british virgin islands                      this privacy policy and our privacy practices will be subject exclusively to the laws of the british virgin islands                                                                                                                                                                                                                                                                                                               "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1LLn-p6XKrV"
      },
      "source": [
        "# Avoid \"Expected Byte but got integer\" error later\n",
        "tac_train[\"Summary\"] = tac_train[\"Summary\"].astype(str)\n",
        "tac_train[\"Original Text\"] = tac_train[\"Original Text\"].astype(str)\n",
        "\n",
        "tac_valid[\"Summary\"] = tac_valid[\"Summary\"].astype(str)\n",
        "tac_valid[\"Original Text\"] = tac_valid[\"Original Text\"].astype(str)\n",
        "\n",
        "tac_test[\"Summary\"] = tac_test[\"Summary\"].astype(str)\n",
        "tac_test[\"Original Text\"] = tac_test[\"Original Text\"].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o4rUteaIrI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aecdf58-86e2-45c9-cd5a-45a41f0adbe9"
      },
      "source": [
        "# View metric\n",
        "metric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
              "Calculates average rouge scores for a list of hypotheses and references\n",
              "Args:\n",
              "    predictions: list of predictions to score. Each predictions\n",
              "        should be a string with tokens separated by spaces.\n",
              "    references: list of reference for each prediction. Each\n",
              "        reference should be a string with tokens separated by spaces.\n",
              "    rouge_types: A list of rouge types to calculate.\n",
              "        Valid names:\n",
              "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
              "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
              "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
              "\"`.\n",
              "        See details in https://github.com/huggingface/datasets/issues/617\n",
              "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
              "    use_agregator: Return aggregates if this is set to True\n",
              "Returns:\n",
              "    rouge1: rouge_1 (precision, recall, f1),\n",
              "    rouge2: rouge_2 (precision, recall, f1),\n",
              "    rougeL: rouge_l (precision, recall, f1),\n",
              "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
              "Examples:\n",
              "\n",
              "    >>> rouge = datasets.load_metric('rouge')\n",
              "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
              "    >>> references = [\"hello there\", \"general kenobi\"]\n",
              "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
              "    >>> print(list(results.keys()))\n",
              "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
              "    >>> print(results[\"rouge1\"])\n",
              "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
              "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
              "    1.0\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9qywopnIrJH"
      },
      "source": [
        "## Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f636d1b-b845-45ac-9bd8-c18ead3b9446"
      },
      "source": [
        "# Import the tokenizer for T5\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
            "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
            "loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oImOxZysb68R"
      },
      "source": [
        "if model_checkpoint in [\"t5-small\"]:\n",
        "    prefix = \"summarize: \"\n",
        "else:\n",
        "    prefix = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3klyvtodYo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b329a83-c38d-4b7b-e33d-b0558cb0cd8f"
      },
      "source": [
        "max(tac_train.astype('str').applymap(lambda x: len(x)).max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc0BSBLIIrJQ"
      },
      "source": [
        "max_input_length = 549\n",
        "max_target_length = 200\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"Original Text\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"Summary\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBzwXVacei8T"
      },
      "source": [
        "train_dataset = Dataset.from_pandas(tac_train)\n",
        "val_dataset = Dataset.from_pandas(tac_valid)\n",
        "test_dataset = Dataset.from_pandas(tac_test)\n",
        "\n",
        "raw_datasets = datasets.DatasetDict({\"train\" : train_dataset, \"validation\" : val_dataset, \"test\" : test_dataset})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYPzV44kgoPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfee052-d3a9-49fd-eb99-d035d5731a41"
      },
      "source": [
        "raw_datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Summary', 'Original Text', '__index_level_0__'],\n",
              "        num_rows: 607\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Summary', 'Original Text', '__index_level_0__'],\n",
              "        num_rows: 208\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Summary', 'Original Text', '__index_level_0__'],\n",
              "        num_rows: 53\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c8e20458bfd548e08920af57a98c82e9",
            "46157fed35304862a20a40683cea290d",
            "77badf3010c7448aa7224b1902c0b7af"
          ]
        },
        "outputId": "130ed274-5be4-4c34-e57b-b27fb5ae0c91"
      },
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8e20458bfd548e08920af57a98c82e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46157fed35304862a20a40683cea290d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77badf3010c7448aa7224b1902c0b7af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c45b4f4-ad4f-4861-8940-c7968ea9a2be"
      },
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainingArguments\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
            "Model config T5Config {\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.9.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zF6P42Lb68W"
      },
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmvbnJ9JIrJd"
      },
      "source": [
        "# define evaluation function\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHren3BlG8v-"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXuFTAzDIrJe"
      },
      "source": [
        "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6jBWlNYB1fT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b64d04-a417-46dd-a97b-d6bf7885adbe"
      },
      "source": [
        "# 1. Start a W&B run\n",
        "wandb.init(project='t5summarizer', entity='belin')\n",
        "run_name = wandb.run.name\n",
        "wandb.config\n",
        "wandb.log({'loss': 0.2, 'epoch': 1})\n",
        "%env WANDB_LOG_MODEL=true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbelin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.11.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">splendid-eon-57</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/belin/t5summarizer\" target=\"_blank\">https://wandb.ai/belin/t5summarizer</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/belin/t5summarizer/runs/11cot1ae\" target=\"_blank\">https://wandb.ai/belin/t5summarizer/runs/11cot1ae</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210801_142511-11cot1ae</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "env: WANDB_LOG_MODEL=true\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku0zC_3t9EL8",
        "outputId": "158b6afc-6f06-4c13-dfc4-dc737f3c1e48"
      },
      "source": [
        "# Hyperparameter optimisation using Ray Tune\n",
        "import ray\n",
        "ray.shutdown()\n",
        "ray.init(log_to_driver=True, ignore_reinit_error=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:25:17,655\tINFO resource_spec.py:231 -- Starting Ray with 7.42 GiB memory available for workers and up to 3.73 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2021-08-01 14:25:18,798\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2021-08-01_14-25-17_653499_62/sockets/plasma_store',\n",
              " 'raylet_ip_address': '172.28.0.2',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2021-08-01_14-25-17_653499_62/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:6379',\n",
              " 'session_dir': '/tmp/ray/session_2021-08-01_14-25-17_653499_62',\n",
              " 'webui_url': 'localhost:8265'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqNbMF1CHf3H"
      },
      "source": [
        "config = {\n",
        "        # These 3 configs below were defined earlier\n",
        "        \"model_name\": model,\n",
        "        # \"task_name\": task_name,\n",
        "        # \"data_dir\": task_data_dir,\n",
        "        \"per_gpu_val_batch_size\": 1,\n",
        "        \"per_gpu_train_batch_size\": tune.choice([1]),\n",
        "        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
        "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
        "        \"num_epochs\": tune.choice([3, 5]),\n",
        "        \"max_steps\": -1,  # We use num_epochs instead.\n",
        "        \"wandb\": {\n",
        "            \"project\": \"pbt_transformers\",\n",
        "            \"reinit\": True,\n",
        "            \"allow_val_change\": True\n",
        "        }\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGIax71xIDqy"
      },
      "source": [
        "Now we can set up our Population Based Training scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip6shHkNICTs"
      },
      "source": [
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "\n",
        "scheduler = PopulationBasedTraining(\n",
        "        time_attr=\"training_iteration\",\n",
        "        metric=\"eval_acc\",\n",
        "        mode=\"max\",\n",
        "        perturbation_interval=2,\n",
        "        hyperparam_mutations={\n",
        "            \"weight_decay\": lambda: tune.uniform(0.0, 0.3).func(None),\n",
        "            \"learning_rate\": lambda: tune.uniform(1e-5, 5e-5).func(None),\n",
        "            \"per_gpu_train_batch_size\": [1],\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvmerUBvIMei"
      },
      "source": [
        "We also create a CLI reporter to view our results from the command line. We specify the hyperparameters we want to see from the command line, as well as what metrics we want to see. The metrics are the inputs to the tune.report we call we make in TuneTransformerTrainer.evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMi3NOkPIJS4"
      },
      "source": [
        "from ray.tune import CLIReporter\n",
        "\n",
        "reporter = CLIReporter(\n",
        "        parameter_columns={\n",
        "            \"weight_decay\": \"w_decay\",\n",
        "            \"learning_rate\": \"lr\",\n",
        "            \"per_gpu_train_batch_size\": \"train_bs/gpu\",\n",
        "            \"num_epochs\": \"num_epochs\"\n",
        "        },\n",
        "        metric_columns=[\n",
        "            \"eval_acc\", \"eval_loss\", \"epoch\", \"training_iteration\"\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjDlaDUU90ui"
      },
      "source": [
        "def train_transformer(config, checkpoint_dir=None):\n",
        "  train_dataset, eval_dataset = tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"]\n",
        "\n",
        "  training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=tune.get_trial_dir(),\n",
        "        learning_rate=config[\"learning_rate\"],\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        evaluation_strategy = \"epoch\",\n",
        "        # Run eval after every epoch.\n",
        "        eval_steps=(len(train_dataset) // config[\"per_gpu_train_batch_size\"]) +\n",
        "        1,\n",
        "        # We explicitly set save to 0, and do checkpointing in evaluate instead\n",
        "        save_steps=0,\n",
        "        num_train_epochs=config[\"num_epochs\"],\n",
        "        max_steps=config[\"max_steps\"],\n",
        "        per_device_train_batch_size=config[\"per_gpu_train_batch_size\"],\n",
        "        per_device_eval_batch_size=config[\"per_gpu_val_batch_size\"],\n",
        "        warmup_steps=500,\n",
        "        weight_decay=config[\"weight_decay\"],\n",
        "        logging_dir=\"./logs\",\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnWPeLyWIb76"
      },
      "source": [
        "Finally, we pass in our training function, config, PBT scheduler, and reporter to tune:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy5X41IzIVd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61d270d-fc95-4e4b-9248-976c69387bf2"
      },
      "source": [
        "analysis = tune.run(\n",
        "        train_transformer,\n",
        "        resources_per_trial={\n",
        "            \"cpu\": 1,\n",
        "            \"gpu\": 1\n",
        "        },\n",
        "        config=config,\n",
        "        num_samples=3,\n",
        "        scheduler=scheduler,\n",
        "        keep_checkpoints_num=3,\n",
        "        checkpoint_score_attr=\"training_iteration\",\n",
        "        progress_reporter=reporter,\n",
        "        local_dir=\"./ray_results/\",\n",
        "        name=\"tune_transformer_pbt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:25:20,987\tWARNING worker.py:1134 -- The dashboard on node 1120301385f4 failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/dashboard/dashboard.py\", line 961, in <module>\n",
            "    dashboard.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/dashboard/dashboard.py\", line 576, in run\n",
            "    aiohttp.web.run_app(self.app, host=self.host, port=self.port)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/aiohttp/web.py\", line 508, in run_app\n",
            "    loop.run_until_complete(main_task)\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 587, in run_until_complete\n",
            "    return future.result()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/aiohttp/web.py\", line 411, in _run_app\n",
            "    await site.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/aiohttp/web_runner.py\", line 128, in start\n",
            "    reuse_port=self._reuse_port,\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1389, in create_server\n",
            "    % (sa, err.strerror.lower())) from None\n",
            "OSError: [Errno 99] error while attempting to bind on address ('::1', 8265, 0, 0): cannot assign requested address\n",
            "\n",
            "2021-08-01 14:25:24,407\tWARNING util.py:137 -- The `start_trial` operation took 2.009049654006958 seconds to complete, which may be a performance bottleneck.\n",
            "\u001b[2m\u001b[36m(pid=805)\u001b[0m 2021-08-01 14:25:26.875940: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-01 14:25:43,692\tWARNING util.py:137 -- The `experiment_checkpoint` operation took 19.28371787071228 seconds to complete, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 7.2/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 1/2 CPUs, 1/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (2 PENDING, 1 RUNNING)\n",
            "+-------------------------------+----------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status   | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+----------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | RUNNING  |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | PENDING  |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | PENDING  |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+----------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:26:01,700\tWARNING util.py:137 -- The `experiment_checkpoint` operation took 17.65482997894287 seconds to complete, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 7.5/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (2 PENDING, 1 TERMINATED)\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status     | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+------------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | TERMINATED |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | PENDING    |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | PENDING    |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:26:03,878\tWARNING util.py:137 -- The `start_trial` operation took 2.1643381118774414 seconds to complete, which may be a performance bottleneck.\n",
            "\u001b[2m\u001b[36m(pid=806)\u001b[0m 2021-08-01 14:26:07.274533: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-01 14:26:22,847\tWARNING util.py:137 -- The `experiment_checkpoint` operation took 18.96555185317993 seconds to complete, which may be a performance bottleneck.\n",
            "2021-08-01 14:26:22,856\tWARNING ray_trial_executor.py:414 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 8.1/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 1/2 CPUs, 1/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (1 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status     | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+------------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | TERMINATED |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | RUNNING    |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | PENDING    |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:26:39,983\tWARNING util.py:137 -- The `experiment_checkpoint` operation took 16.90284013748169 seconds to complete, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 7.7/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (1 PENDING, 2 TERMINATED)\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status     | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+------------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | TERMINATED |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | TERMINATED |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | PENDING    |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:26:42,405\tWARNING util.py:137 -- The `start_trial` operation took 2.411698818206787 seconds to complete, which may be a performance bottleneck.\n",
            "\u001b[2m\u001b[36m(pid=920)\u001b[0m 2021-08-01 14:26:46.748371: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-01 14:27:01,900\tWARNING util.py:137 -- The `experiment_checkpoint` operation took 19.49385952949524 seconds to complete, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 8.0/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 1/2 CPUs, 1/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (1 RUNNING, 2 TERMINATED)\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status     | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+------------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | TERMINATED |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | TERMINATED |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | RUNNING    |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-01 14:27:18,990\tWARNING util.py:137 -- The `experiment_checkpoint` operation took 16.840167999267578 seconds to complete, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 7.7/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (3 TERMINATED)\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status     | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+------------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | TERMINATED |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | TERMINATED |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | TERMINATED |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Memory usage on this node: 7.7/12.7 GiB\n",
            "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.42 GiB heap, 0.0/2.54 GiB objects (0/1.0 GPUType:V100)\n",
            "Result logdir: /content/ray_results/tune_transformer_pbt\n",
            "Number of trials: 3 (3 TERMINATED)\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "| Trial name                    | status     | loc   |   w_decay |          lr |   train_bs/gpu |   num_epochs |\n",
            "|-------------------------------+------------+-------+-----------+-------------+----------------+--------------|\n",
            "| train_transformer_4d655_00000 | TERMINATED |       | 0.285214  | 2.49816e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00001 | TERMINATED |       | 0.179598  | 3.92798e-05 |              1 |            5 |\n",
            "| train_transformer_4d655_00002 | TERMINATED |       | 0.0467984 | 1.62407e-05 |              1 |            3 |\n",
            "+-------------------------------+------------+-------+-----------+-------------+----------------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzABDVcIrJg"
      },
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bliy8zgjIrJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6192b1-3932-416e-982a-73f9af2475bf"
      },
      "source": [
        "batch_size = 1\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    \"test-summarization\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.015,\n",
        "    save_total_limit=1,\n",
        "    num_train_epochs=5,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"wandb\",\n",
        "    adafactor = True, # recommended to use adafactor instead of adamw for T5\n",
        "    learning_rate = 1e-4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imY1oC3SIrJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde329c0-61a0-47d0-b300-94a6d2a73e92"
      },
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using amp fp16 backend\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzYrnXYAINOa"
      },
      "source": [
        "# Clear space \n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB4ifGXtK2g4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a874c8-a55c-46aa-9035-71b0247a8528"
      },
      "source": [
        "# \"model_T5\" is saved in wandb.run.dir & will be uploaded at the end of training\n",
        "trainer.save_model(os.path.join(wandb.run.dir, \"model.T5\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/wandb/run-20210801_142511-11cot1ae/files/model.T5\n",
            "Configuration saved in /content/wandb/run-20210801_142511-11cot1ae/files/model.T5/config.json\n",
            "Model weights saved in /content/wandb/run-20210801_142511-11cot1ae/files/model.T5/pytorch_model.bin\n",
            "tokenizer config file saved in /content/wandb/run-20210801_142511-11cot1ae/files/model.T5/tokenizer_config.json\n",
            "Special tokens file saved in /content/wandb/run-20210801_142511-11cot1ae/files/model.T5/special_tokens_map.json\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf2da24-ede9-4d4b-e0fd-0c04d71921d1"
      },
      "source": [
        "# Train the Model\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running training *****\n",
            "  Num examples = 607\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3035\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1310: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3035' max='3035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3035/3035 08:12, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.831500</td>\n",
              "      <td>2.679664</td>\n",
              "      <td>31.420700</td>\n",
              "      <td>12.378000</td>\n",
              "      <td>27.145000</td>\n",
              "      <td>27.150100</td>\n",
              "      <td>12.538500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.888400</td>\n",
              "      <td>2.426994</td>\n",
              "      <td>37.327100</td>\n",
              "      <td>20.596400</td>\n",
              "      <td>34.618200</td>\n",
              "      <td>34.742300</td>\n",
              "      <td>12.576900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.420600</td>\n",
              "      <td>2.363035</td>\n",
              "      <td>38.050700</td>\n",
              "      <td>21.517900</td>\n",
              "      <td>35.418500</td>\n",
              "      <td>35.548400</td>\n",
              "      <td>12.129800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.346900</td>\n",
              "      <td>2.348763</td>\n",
              "      <td>37.727700</td>\n",
              "      <td>21.024800</td>\n",
              "      <td>35.104700</td>\n",
              "      <td>35.234300</td>\n",
              "      <td>12.408700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.068200</td>\n",
              "      <td>2.340661</td>\n",
              "      <td>38.363600</td>\n",
              "      <td>21.719400</td>\n",
              "      <td>35.559400</td>\n",
              "      <td>35.671600</td>\n",
              "      <td>12.375000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to test-summarization/checkpoint-500\n",
            "Configuration saved in test-summarization/checkpoint-500/config.json\n",
            "Model weights saved in test-summarization/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-500/special_tokens_map.json\n",
            "Deleting older checkpoint [test-summarization/checkpoint-3000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 208\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test-summarization/checkpoint-1000\n",
            "Configuration saved in test-summarization/checkpoint-1000/config.json\n",
            "Model weights saved in test-summarization/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-1000/special_tokens_map.json\n",
            "Deleting older checkpoint [test-summarization/checkpoint-500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 208\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test-summarization/checkpoint-1500\n",
            "Configuration saved in test-summarization/checkpoint-1500/config.json\n",
            "Model weights saved in test-summarization/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-1500/special_tokens_map.json\n",
            "Deleting older checkpoint [test-summarization/checkpoint-1000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 208\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test-summarization/checkpoint-2000\n",
            "Configuration saved in test-summarization/checkpoint-2000/config.json\n",
            "Model weights saved in test-summarization/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [test-summarization/checkpoint-1500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 208\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test-summarization/checkpoint-2500\n",
            "Configuration saved in test-summarization/checkpoint-2500/config.json\n",
            "Model weights saved in test-summarization/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-2500/special_tokens_map.json\n",
            "Deleting older checkpoint [test-summarization/checkpoint-2000] due to args.save_total_limit\n",
            "Saving model checkpoint to test-summarization/checkpoint-3000\n",
            "Configuration saved in test-summarization/checkpoint-3000/config.json\n",
            "Model weights saved in test-summarization/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in test-summarization/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in test-summarization/checkpoint-3000/special_tokens_map.json\n",
            "Deleting older checkpoint [test-summarization/checkpoint-2500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 208\n",
            "  Batch size = 1\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Using amp fp16 backend\n",
            "Saving model checkpoint to /tmp/tmp91urmwdt\n",
            "Configuration saved in /tmp/tmp91urmwdt/config.json\n",
            "Model weights saved in /tmp/tmp91urmwdt/pytorch_model.bin\n",
            "tokenizer config file saved in /tmp/tmp91urmwdt/tokenizer_config.json\n",
            "Special tokens file saved in /tmp/tmp91urmwdt/special_tokens_map.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3035, training_loss=2.6098846347563742, metrics={'train_runtime': 487.8748, 'train_samples_per_second': 6.221, 'train_steps_per_second': 6.221, 'total_flos': 48823497523200.0, 'train_loss': 2.6098846347563742, 'epoch': 5.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj69GVD_NGrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317f3af0-026c-4bfa-f486-a6e160a3e018"
      },
      "source": [
        "# Save a model file from the current directory\n",
        "wandb.save('trainer.T5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-15ubb2RUJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8628cb25-a1ef-487d-dd83-683bfd27830e"
      },
      "source": [
        "# Save the model\n",
        "wandb.run.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FbHZvBW7f2s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b62a606657444042a77ab2b99f71dea8"
          ]
        },
        "outputId": "972dda14-775a-48b2-9183-71ad6818adb3"
      },
      "source": [
        "# Finish WADNB run\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 711<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b62a606657444042a77ab2b99f71dea8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 232.20MB of 232.20MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max="
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210801_142511-11cot1ae/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210801_142511-11cot1ae/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>loss</td><td>0.2</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>_runtime</td><td>660</td></tr><tr><td>_timestamp</td><td>1627828571</td></tr><tr><td>_step</td><td>12</td></tr><tr><td>train/loss</td><td>2.0682</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>3035</td></tr><tr><td>eval/loss</td><td>2.34066</td></tr><tr><td>eval/rouge1</td><td>38.3636</td></tr><tr><td>eval/rouge2</td><td>21.7194</td></tr><tr><td>eval/rougeL</td><td>35.5594</td></tr><tr><td>eval/rougeLsum</td><td>35.6716</td></tr><tr><td>eval/gen_len</td><td>12.375</td></tr><tr><td>eval/runtime</td><td>27.3285</td></tr><tr><td>eval/samples_per_second</td><td>7.611</td></tr><tr><td>eval/steps_per_second</td><td>7.611</td></tr><tr><td>train/train_runtime</td><td>487.8748</td></tr><tr><td>train/train_samples_per_second</td><td>6.221</td></tr><tr><td>train/train_steps_per_second</td><td>6.221</td></tr><tr><td>train/total_flos</td><td>48823497523200.0</td></tr><tr><td>train/train_loss</td><td>2.60988</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>loss</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>_runtime</td><td></td></tr><tr><td>_timestamp</td><td></td></tr><tr><td>_step</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/rouge1</td><td></td></tr><tr><td>eval/rouge2</td><td></td></tr><tr><td>eval/rougeL</td><td></td></tr><tr><td>eval/rougeLsum</td><td></td></tr><tr><td>eval/gen_len</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 6 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">splendid-eon-57</strong>: <a href=\"https://wandb.ai/belin/t5summarizer/runs/11cot1ae\" target=\"_blank\">https://wandb.ai/belin/t5summarizer/runs/11cot1ae</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ejxP64h70gs"
      },
      "source": [
        "Test on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77GlxbqkRR_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e75b77-0157-4a53-b581-563c1b8dc149"
      },
      "source": [
        "# See what's in the test data\n",
        "tokenized_datasets[\"test\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Original Text', 'Summary', '__index_level_0__', 'attention_mask', 'input_ids', 'labels'],\n",
              "    num_rows: 53\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioNPNOhISv8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecc2574-1049-4314-d3f8-745ac17f9fa9"
      },
      "source": [
        "# Make predictions\n",
        "predictions = trainer.predict(tokenized_datasets[\"test\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Original Text, __index_level_0__, Summary.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 53\n",
            "  Batch size = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:07]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo-zegdjUYm-"
      },
      "source": [
        "# Create a function to decode predictions\n",
        "def translate_predictions(prediction):\n",
        "  for i in prediction:\n",
        "    decoded_prediction = tokenizer.batch_decode(i, skip_special_tokens=True)\n",
        "    return decoded_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6-PKNgKTOLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f621bd0-962d-40e4-88d8-a58955629149"
      },
      "source": [
        "# Decode predictions\n",
        "predictions = pd.DataFrame(predictions)\n",
        "decoded_predictions = predictions.apply(translate_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py:305: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  values = np.array([convert(v) for v in values])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHWrUVNhV4wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2feb2c13-e5dc-4c84-9eb5-edcc73e8e03d"
      },
      "source": [
        "# Maximise column width\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngd9cm7OBpoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30490aa-1c63-4cbb-b970-afd019d6a5da"
      },
      "source": [
        "# Take a random sample of the dataset\n",
        "import random\n",
        "random.seed(12)\n",
        "randomlist = []\n",
        "for i in range(0,20):\n",
        "  n = random.randint(1,len(tokenized_datasets[\"test\"]))\n",
        "  randomlist.append(n)\n",
        "print(randomlist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[31, 18, 43, 34, 43, 23, 10, 25, 1, 24, 31, 18, 42, 52, 30, 45, 39, 15, 36, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vjfBmr9BvFb"
      },
      "source": [
        "# See the corresponding decoded predictions\n",
        "samples = pd.concat([decoded_predictions.iloc[i] for i in randomlist], axis = 1).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FqscxsuBvMg"
      },
      "source": [
        "# Find the originals \n",
        "originals = pd.concat([tac_test.iloc[i] for i in randomlist], axis = 1).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCWDRghBzps"
      },
      "source": [
        "# Reset sample index\n",
        "samples.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OD2prjhBzsd"
      },
      "source": [
        "# Reset originals index\n",
        "originals.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjS8WIXAEGhM"
      },
      "source": [
        "# Combine the datasets to make a comparisons dataframe\n",
        "comparisons = pd.concat([samples, originals], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QYbD-QOEGnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e279352b-c30f-4075-b33b-d14b386057a6"
      },
      "source": [
        "# Label and look at dataframe\n",
        "comparisons.set_axis(['T5 Prediction', 'Summary', 'Original Text'], axis=1, inplace=True)\n",
        "comparisons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T5 Prediction</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Original Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the court of law governing the terms is in location russian federation russia</td>\n",
              "      <td>the court of law governing the terms is in location st  petersburg  russia</td>\n",
              "      <td>in these terms and other special documents  the vk site administration  hereinafter the site administration  administration  is understood as llc  v kontakte   a legal entity created under the laws of the russian federation and registered at prem 1 n  bld 12 14  lit a  khersonskaya st   st petersburg  russia  191024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mewe reserves the right to remove objectionable content without notice</td>\n",
              "      <td>your content can be deleted if you violate the terms</td>\n",
              "      <td>mewe reserves the right to remove objectionable content without notice mewe can remove any content or information you post at mewe if we believe that it violates our terms of service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the service does not use the brainly services</td>\n",
              "      <td>users agree not to submit libelous  harassing or threatening content</td>\n",
              "      <td>not use the brainly services do anything unlawful  misleading  malicious  or discriminatory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this service uses targeted cookies for advertising</td>\n",
              "      <td>this service tracks you on other websites</td>\n",
              "      <td>we also use retargeting cookies to present you with patreon advertising on other websites</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the service does not use the brainly services</td>\n",
              "      <td>users agree not to submit libelous  harassing or threatening content</td>\n",
              "      <td>not use the brainly services do anything unlawful  misleading  malicious  or discriminatory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the service is committed to the privacy of users</td>\n",
              "      <td>this service respects your browsers do not track  dnt  headers</td>\n",
              "      <td>one concrete way we commit to user privacy is by honoring do not track  dnt  browser settings theres no consensus on how best to do this but  we have adopted an approach that we believe honors the fundamental pro privacy aims of the dnt standard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you can use googles privacy policy for your personal data</td>\n",
              "      <td>users are subject to googles privacy policy</td>\n",
              "      <td>by using or visiting the youtube website or any youtube products  software  data feeds  and services provided to you on  from  or through the youtube website  collectively the  service   you signify your agreement to  1  these terms and conditions  the  terms of service     2  googles privacy policy  found at and incorporated herein by reference  and  3  youtubes community guidelines  found at and also incorporated herein by reference</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the service does not promote or condone any content</td>\n",
              "      <td>discogs does not condone any ideas contained in the items listed via the service</td>\n",
              "      <td>e  we do not promote or condone any ideas or messages contained in the user generated content available through the service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>any liability on behalf of the service is only limited to 1 000</td>\n",
              "      <td>any liability on behalf of the service is only limited to   1 000</td>\n",
              "      <td>and  ii  for any damages  losses and or causes of action exceeding one thousand u s dollars  us  1 000  in the aggregate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>no logs are kept at any part</td>\n",
              "      <td>user logs are never stored at any component of infrastructure</td>\n",
              "      <td>we will never keep logs at any component of our infrastructure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>the court of law governing the terms is in location russian federation russia</td>\n",
              "      <td>the court of law governing the terms is in location st  petersburg  russia</td>\n",
              "      <td>in these terms and other special documents  the vk site administration  hereinafter the site administration  administration  is understood as llc  v kontakte   a legal entity created under the laws of the russian federation and registered at prem 1 n  bld 12 14  lit a  khersonskaya st   st petersburg  russia  191024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>mewe reserves the right to remove objectionable content without notice</td>\n",
              "      <td>your content can be deleted if you violate the terms</td>\n",
              "      <td>mewe reserves the right to remove objectionable content without notice mewe can remove any content or information you post at mewe if we believe that it violates our terms of service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>you are not allowed to use the terms carfax car fox or any derivatives</td>\n",
              "      <td>users are not allowed to use pseudonyms  as trust and transparency between users regarding their identities is relevant to the service</td>\n",
              "      <td>you may not impersonate any person or entity  or otherwise mislead as to the origin of the content you share with carfax when you register you may not use the terms carfax  car fox or any derivatives or such terms as part of your screenname or username</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>the service does not guarantee the accuracy of the terms</td>\n",
              "      <td>usernames can be rejected or changed for any reason</td>\n",
              "      <td>force forfeiture of any username for any reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>the court of law governing the terms is in all jurisdictions</td>\n",
              "      <td>the court of law governing the terms is in a jurisdiction that is less friendly to user privacy protection</td>\n",
              "      <td>while our policy is based on the us law we apply this same policy globally to all jurisdictions in which our services are available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>google analytics mixpanel and fabric analytic services can address your behavior</td>\n",
              "      <td>google analytics  facebook analytics  mixpanel and fabric analytic are used for statistics</td>\n",
              "      <td>we use google analytics  facebook analytics  mixpanel and fabric analytic services to be able to address you more relevant messages based on your behavior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>the court of law governing the terms is in location texas</td>\n",
              "      <td>couchsurfing keeps the license on your content  even after you close your account</td>\n",
              "      <td>sections 3 5  release   4  member conduct and content   5  submissions   9  trademarks   11  third party content   14  members representations and warranties   15  disclaimer of warranties   16  limits on liability   17  indemnity   19  disputes   and this section 20  miscellaneous  shall survive any termination or expiration of these terms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>the service reserves the right to revoke user permissions for any reason</td>\n",
              "      <td>the service can delete your account without prior notice</td>\n",
              "      <td>these provisions notwithstanding  the administration of the service reserves the right to revoke any users access permissions  at any time  for any reason  except as limited by law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>you are only 13 years old</td>\n",
              "      <td>this service is only available to users over 13 years old</td>\n",
              "      <td>if you are under the age of 13  you are not permitted to use the services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>any liability on behalf of the service is only limited to 1 000</td>\n",
              "      <td>any liability on behalf of the service is only limited to   1 000</td>\n",
              "      <td>and  ii  for any damages  losses and or causes of action exceeding one thousand u s dollars  us  1 000  in the aggregate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                       T5 Prediction  ...                                                                                                                                                                                                                                                                                                                                                                                                                                            Original Text\n",
              "0   the court of law governing the terms is in location russian federation russia     ...  in these terms and other special documents  the vk site administration  hereinafter the site administration  administration  is understood as llc  v kontakte   a legal entity created under the laws of the russian federation and registered at prem 1 n  bld 12 14  lit a  khersonskaya st   st petersburg  russia  191024                                                                                                                          \n",
              "1   mewe reserves the right to remove objectionable content without notice            ...  mewe reserves the right to remove objectionable content without notice mewe can remove any content or information you post at mewe if we believe that it violates our terms of service                                                                                                                                                                                                                                                                 \n",
              "2   the service does not use the brainly services                                     ...  not use the brainly services do anything unlawful  misleading  malicious  or discriminatory                                                                                                                                                                                                                                                                                                                                                            \n",
              "3   this service uses targeted cookies for advertising                                ...  we also use retargeting cookies to present you with patreon advertising on other websites                                                                                                                                                                                                                                                                                                                                                              \n",
              "4   the service does not use the brainly services                                     ...  not use the brainly services do anything unlawful  misleading  malicious  or discriminatory                                                                                                                                                                                                                                                                                                                                                            \n",
              "5   the service is committed to the privacy of users                                  ...  one concrete way we commit to user privacy is by honoring do not track  dnt  browser settings theres no consensus on how best to do this but  we have adopted an approach that we believe honors the fundamental pro privacy aims of the dnt standard                                                                                                                                                                                               \n",
              "6   you can use googles privacy policy for your personal data                         ...  by using or visiting the youtube website or any youtube products  software  data feeds  and services provided to you on  from  or through the youtube website  collectively the  service   you signify your agreement to  1  these terms and conditions  the  terms of service     2  googles privacy policy  found at and incorporated herein by reference  and  3  youtubes community guidelines  found at and also incorporated herein by reference \n",
              "7   the service does not promote or condone any content                               ...   e  we do not promote or condone any ideas or messages contained in the user generated content available through the service                                                                                                                                                                                                                                                                                                                           \n",
              "8   any liability on behalf of the service is only limited to 1 000                   ...  and  ii  for any damages  losses and or causes of action exceeding one thousand u s dollars  us  1 000  in the aggregate                                                                                                                                                                                                                                                                                                                               \n",
              "9   no logs are kept at any part                                                      ...  we will never keep logs at any component of our infrastructure                                                                                                                                                                                                                                                                                                                                                                                         \n",
              "10  the court of law governing the terms is in location russian federation russia     ...  in these terms and other special documents  the vk site administration  hereinafter the site administration  administration  is understood as llc  v kontakte   a legal entity created under the laws of the russian federation and registered at prem 1 n  bld 12 14  lit a  khersonskaya st   st petersburg  russia  191024                                                                                                                          \n",
              "11  mewe reserves the right to remove objectionable content without notice            ...  mewe reserves the right to remove objectionable content without notice mewe can remove any content or information you post at mewe if we believe that it violates our terms of service                                                                                                                                                                                                                                                                 \n",
              "12  you are not allowed to use the terms carfax car fox or any derivatives            ...  you may not impersonate any person or entity  or otherwise mislead as to the origin of the content you share with carfax when you register you may not use the terms carfax  car fox or any derivatives or such terms as part of your screenname or username                                                                                                                                                                                           \n",
              "13  the service does not guarantee the accuracy of the terms                          ...  force forfeiture of any username for any reason                                                                                                                                                                                                                                                                                                                                                                                                        \n",
              "14  the court of law governing the terms is in all jurisdictions                      ...  while our policy is based on the us law we apply this same policy globally to all jurisdictions in which our services are available                                                                                                                                                                                                                                                                                                                    \n",
              "15  google analytics mixpanel and fabric analytic services can address your behavior  ...  we use google analytics  facebook analytics  mixpanel and fabric analytic services to be able to address you more relevant messages based on your behavior                                                                                                                                                                                                                                                                                             \n",
              "16  the court of law governing the terms is in location texas                         ...  sections 3 5  release   4  member conduct and content   5  submissions   9  trademarks   11  third party content   14  members representations and warranties   15  disclaimer of warranties   16  limits on liability   17  indemnity   19  disputes   and this section 20  miscellaneous  shall survive any termination or expiration of these terms                                                                                                \n",
              "17  the service reserves the right to revoke user permissions for any reason          ...  these provisions notwithstanding  the administration of the service reserves the right to revoke any users access permissions  at any time  for any reason  except as limited by law                                                                                                                                                                                                                                                                   \n",
              "18  you are only 13 years old                                                         ...  if you are under the age of 13  you are not permitted to use the services                                                                                                                                                                                                                                                                                                                                                                              \n",
              "19  any liability on behalf of the service is only limited to 1 000                   ...  and  ii  for any damages  losses and or causes of action exceeding one thousand u s dollars  us  1 000  in the aggregate                                                                                                                                                                                                                                                                                                                               \n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv-NYqO855cH"
      },
      "source": [
        "# Convert to csv\n",
        "decoded_predictions.to_csv(\"decoded_predictions_T5_nodups.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6xbpDDKfI3n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "4401fea5-f82e-4cf2-9cd8-fd4fe97d64f2"
      },
      "source": [
        "# Download predictions made\n",
        "from google.colab import files\n",
        "files.download(\"decoded_predictions_T5_nodups.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e46c58b8-48fa-421b-bfcf-49ac5d45f006\", \"decoded_predictions_T5_nodups.csv\", 3344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CEJ9Go96ATY"
      },
      "source": [
        "# Comparisons dataframe to csv\n",
        "comparisons.to_csv(\"comparisons_T5_nodups.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPlQAI7T9ds_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "80154ac0-9ea7-4332-8f3d-78f644b619a2"
      },
      "source": [
        "# Download the file\n",
        "files.download(\"comparisons_T5_nodups.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f61ce609-400e-4432-830f-98dbf9329a08\", \"comparisons_T5_nodups.csv\", 6279)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}